{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing for Model Building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Genres to Vector Format:\n",
    "\n",
    "# Use one-hot encoding or count vectorizer to transform genres into a numerical format.\n",
    "# Example: Adventure|Animation → [1, 1, 0, 0, ...]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "final_data = pd.read_csv('datasets/final_data.csv')\n",
    "final_data['genres_list'] = final_data['genres'].apply(lambda x: x.split('|'))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = pd.DataFrame(mlb.fit_transform(final_data['genres_list']), columns=mlb.classes_)\n",
    "final_data = pd.concat([final_data, genres_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.to_datetime(): Converts the rating_timestamp column from string to datetime64 format.\n",
    "\n",
    ".astype(int): Converts the datetime objects to integers representing the number of nanoseconds since the epoch. Dividing by 10^9 converts nanoseconds to seconds.\n",
    "\n",
    "MinMaxScaler: Scales both rating and the converted rating_timestamp to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rating  rating_timestamp\n",
      "0  0.777778          0.189360\n",
      "1  0.666667          0.470679\n",
      "2  0.777778          0.239560\n",
      "3  0.333333          0.200734\n",
      "4  0.333333          0.045221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the 'rating_timestamp' column to numeric (seconds since epoch)\n",
    "final_data['rating_timestamp'] = pd.to_datetime(final_data['rating_timestamp']).astype('int64') // 10**9\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply MinMaxScaler to 'rating' and 'rating_timestamp'\n",
    "final_data[['rating', 'rating_timestamp']] = scaler.fit_transform(final_data[['rating', 'rating_timestamp']])\n",
    "\n",
    "# Check the scaled values\n",
    "print(final_data[['rating', 'rating_timestamp']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId    1         2         3       4       5         6       7       \\\n",
      "userId                                                                    \n",
      "1        0.000000  0.666667  0.000000     0.0     0.0  0.000000     0.0   \n",
      "2        0.000000  0.000000  0.777778     0.0     0.0  0.000000     0.0   \n",
      "3        0.777778  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "4        0.000000  0.000000  0.000000     0.0     0.0  0.555556     0.0   \n",
      "5        0.000000  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "...           ...       ...       ...     ...     ...       ...     ...   \n",
      "137031   0.000000  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "137277   0.000000  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "137717   0.000000  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "138301   0.000000  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "138406   0.000000  0.000000  0.000000     0.0     0.0  0.000000     0.0   \n",
      "\n",
      "movieId  8       9         10      ...  130984  131011  131013  131015  \\\n",
      "userId                             ...                                   \n",
      "1           0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "2           0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "3           0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "4           0.0     0.0  0.777778  ...     0.0     0.0     0.0     0.0   \n",
      "5           0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "...         ...     ...       ...  ...     ...     ...     ...     ...   \n",
      "137031      0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "137277      0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "137717      0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "138301      0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "138406      0.0     0.0  0.000000  ...     0.0     0.0     0.0     0.0   \n",
      "\n",
      "movieId  131031  131054  131082  131164  131170  131258  \n",
      "userId                                                   \n",
      "1           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "3           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "4           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "5           0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "...         ...     ...     ...     ...     ...     ...  \n",
      "137031      0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "137277      0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "137717      0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "138301      0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "138406      0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[2667 rows x 19011 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prepare User-Item Matrix:\n",
    "\n",
    "# Create a matrix where rows are userId, columns are movieId, and values are ratings.\n",
    "# This matrix is the input for collaborative filtering.\n",
    "\n",
    "user_item_matrix = final_data.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n",
    "print(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and testing sets:\n",
    "\n",
    "# For user-item matrices, consider splitting on user interactions or time.\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(final_data[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Choose a Recommendation Algorithm\n",
    "\n",
    "\n",
    "    Decide which approach fits your goals:\n",
    "\n",
    "    Collaborative Filtering:\n",
    "        Uses user-item interaction data.\n",
    "\n",
    "    Techniques:\n",
    "        User-Based Collaborative Filtering: Recommends based on similar users.\n",
    "\n",
    "        Item-Based Collaborative Filtering: Recommends based on similar items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collaborative Filtering\n",
    "Collaborative filtering relies on user-item interaction data, such as movie ratings, to recommend items. It assumes that if users share similar preferences for some items, they may like other similar items.\n",
    "\n",
    "Techniques:\n",
    "User-Based Collaborative Filtering: Recommends movies that users with similar tastes liked.\n",
    "\n",
    "Example: If User A and User B both like movies X and Y, and User A also likes Z, then Z will be recommended to User B.\n",
    "Steps:\n",
    "Calculate similarity between users (e.g., cosine similarity, Pearson correlation).\n",
    "Identify the nearest neighbors (users most similar to the target user).\n",
    "Aggregate their preferences to make recommendations.\n",
    "Item-Based Collaborative Filtering: Recommends movies similar to those the user has already rated highly.\n",
    "\n",
    "Example: If movies X and Y are rated similarly by many users, and User A likes X, then Y will be recommended to User A.\n",
    "Steps:\n",
    "Calculate similarity between items (e.g., cosine similarity, Pearson correlation).\n",
    "Find similar items to those the target user liked.\n",
    "Aggregate ratings for those items to recommend.\n",
    "Implementation Example:\n",
    "Using the Surprise library for collaborative filtering with the SVD algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD (Singular Value Decomposition): A matrix factorization technique that reduces the dimensionality of the user-item interaction matrix to discover latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for user 1: [105, 104]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Example dataset\n",
    "data_dict = {\n",
    "    'userId': [1, 1, 1, 2, 2, 3, 3, 3, 4, 4],\n",
    "    'movieId': [101, 102, 103, 101, 104, 102, 103, 105, 101, 105],\n",
    "    'rating': [4.0, 5.0, 3.0, 4.0, 5.0, 2.0, 4.0, 5.0, 3.0, 4.0]\n",
    "}\n",
    "ratings_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Convert data into Surprise Dataset format\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train SVD model\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Predict ratings for the testset\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Create a recommendation function\n",
    "def recommend_movies_collaborative(user_id, model, data, n_recommendations=5):\n",
    "    # Get unique movieIds\n",
    "    all_movie_ids = set(data['movieId'])\n",
    "    \n",
    "    # Get movies rated by the user\n",
    "    rated_movie_ids = set(data[data['userId'] == user_id]['movieId'])\n",
    "    \n",
    "    # Find movies not rated by the user\n",
    "    unrated_movie_ids = list(all_movie_ids - rated_movie_ids)\n",
    "    \n",
    "    # Predict ratings for unrated movies\n",
    "    predicted_ratings = [\n",
    "        (movie_id, model.predict(user_id, movie_id).est)\n",
    "        for movie_id in unrated_movie_ids\n",
    "    ]\n",
    "    \n",
    "    # Sort by predicted rating\n",
    "    predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top N recommendations\n",
    "    top_recommendations = [movie_id for movie_id, rating in predicted_ratings[:n_recommendations]]\n",
    "    return top_recommendations\n",
    "\n",
    "# Recommend movies for a specific user\n",
    "user_id = 1  # Change this to the userId you want to test\n",
    "recommendations = recommend_movies_collaborative(user_id, model, ratings_df)\n",
    "print(f\"Recommended movies for user {user_id}: {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Content-Based Filtering\n",
    "Content-based filtering uses the features of items (e.g., genres, tags) to recommend similar items.\n",
    "\n",
    "Steps:\n",
    "Extract features from the data (e.g., genres, tags).\n",
    "Create a profile for each user based on their rated items.\n",
    "Recommend items similar to the user’s preferences using a similarity metric (e.g., cosine similarity, Euclidean distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piyus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antz (1998)', 'Toy Story 2 (1999)', 'Adventures of Rocky and Bullwinkle, The (2000)', \"Emperor's New Groove, The (2000)\", 'Monsters, Inc. (2001)', 'DuckTales: The Movie - Treasure of the Lost Lamp (1990)', 'Wild, The (2006)', 'Shrek the Third (2007)', 'Tale of Despereaux, The (2008)', 'Asterix and the Vikings (Astérix et les Vikings) (2006)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create TF-IDF matrix for genres\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split('|'))\n",
    "tfidf_matrix = tfidf.fit_transform(final_data['genres'])\n",
    "\n",
    "# Calculate similarity between movies\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Recommend movies for a given movie index\n",
    "def recommend_movies(movie_idx, cosine_sim, data, top_n=10):\n",
    "    similar_movies = list(enumerate(cosine_sim[movie_idx]))\n",
    "    similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)\n",
    "    recommendations = [data.iloc[i[0]].title for i in similar_movies[1:top_n+1]]\n",
    "    return recommendations\n",
    "\n",
    "movie_idx = 0  # Index of a specific movie\n",
    "recommendations = recommend_movies(movie_idx, cosine_sim, final_data)\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Hybrid Filtering\n",
    "Hybrid filtering combines collaborative and content-based filtering to address their limitations. It leverages both user-item interaction data and item features.\n",
    "\n",
    "Approaches:\n",
    "Combine predictions from collaborative and content-based models.\n",
    "Use content-based filtering to preprocess data for collaborative filtering.\n",
    "Build a single model that integrates both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched lengths: Collaborative=1, Content=174\n",
      "Final hybrid predictions: [2.0441238677501903]\n"
     ]
    }
   ],
   "source": [
    "# Assuming specific_user_id is the user ID for whom we are making predictions\n",
    "specific_user_id = 1  # Replace with the actual user ID\n",
    "\n",
    "# Get indices of movies rated by this user\n",
    "user_movie_indices = final_data[final_data['userId'] == specific_user_id].index.tolist()\n",
    "\n",
    "# Content-based predictions using cosine similarity\n",
    "content_pred = []\n",
    "for user_rated_idx in user_movie_indices:\n",
    "    # Ensure movie index is within bounds of cosine_sim\n",
    "    if user_rated_idx < cosine_sim.shape[0]:\n",
    "        # Calculate the mean similarity score for each movie\n",
    "        movie_similarities = cosine_sim[user_rated_idx]\n",
    "        content_pred.append(movie_similarities.mean())\n",
    "    else:\n",
    "        content_pred.append(0)  # Fallback for out-of-bounds indices\n",
    "\n",
    "# Collaborative filtering predictions for the specific user\n",
    "collaborative_pred = [\n",
    "    pred.est for pred in model.test(testset) if pred.uid == specific_user_id\n",
    "]\n",
    "\n",
    "# Ensure predictions are normalized to the same length\n",
    "if len(collaborative_pred) != len(content_pred):\n",
    "    print(f\"Mismatched lengths: Collaborative={len(collaborative_pred)}, Content={len(content_pred)}\")\n",
    "    min_len = min(len(collaborative_pred), len(content_pred))\n",
    "    collaborative_pred = collaborative_pred[:min_len]\n",
    "    content_pred = content_pred[:min_len]\n",
    "\n",
    "# Final hybrid prediction\n",
    "final_pred = [0.5 * c + 0.5 * t for c, t in zip(collaborative_pred, content_pred)]\n",
    "\n",
    "print(\"Final hybrid predictions:\", final_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piyus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\piyus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load and preprocess data\n",
    "final_data = pd.read_csv('datasets/final_data.csv')\n",
    "final_data['genres_list'] = final_data['genres'].apply(lambda x: x .split('|'))\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split('|'))\n",
    "tfidf_matrix = tfidf.fit_transform(final_data['genres'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_movies(movie_name):\n",
    "    movie_idx = final_data[final_data['title'] == movie_name].index[0]\n",
    "    similar_movies = list(enumerate(cosine_sim[movie_idx]))\n",
    "    similar_movies = sorted(similar_movies, key=lambda x: x[1], reverse=True)\n",
    "    recommendations = [final_data.iloc[i[0]].title for i in similar_movies[1:11]]\n",
    "    return \", \".join(recommendations)  # Format recommendations in a single row\n",
    "\n",
    "# Create Gradio interface\n",
    "movie_list = final_data['title'].tolist()\n",
    "interface = gr.Interface(\n",
    "    fn=recommend_movies,\n",
    "    inputs=gr.Dropdown(choices=movie_list, label=\"Select a Movie\"),\n",
    "    outputs=gr.Markdown(label=\"Recommended Movies\")\n",
    ")\n",
    "\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
